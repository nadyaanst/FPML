# -*- coding: utf-8 -*-
"""FINPRO ML NYOBA LG

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14ycFvb1j0apT0qLtCZV-a4EC1vpDa9Cf
"""

import numpy as np
import pandas as pd
import os
import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from glob import glob
from PIL import Image
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential

!pip install tensorflow

from google.colab import files
uploaded = files.upload()

import zipfile
import os

zip_path = "rice_leaf_diseases.zip"
extract_path = "/content/rice_leaf_diseases"

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

for root, dirs, files in os.walk(extract_path):
    print(f"Folder: {root}")
    for file in files[:5]:  # tampilkan 5 file pertama
        print(f" - {file}")
    print("------")

base_path = "rice_leaf_diseases/rice_leaf_diseases"

"""EDA RICE LEAF"""

class_names = os.listdir(base_path)
print("Classes found:", class_names)

image_counts = {}
image_paths = {}

for cls in class_names:
    class_dir = os.path.join(base_path, cls)
    images = glob(os.path.join(class_dir, "*.jpg"))
    image_counts[cls] = len(images)
    image_paths[cls] = images

# Display class distribution
plt.figure(figsize=(8,5))
sns.barplot(x=list(image_counts.keys()), y=list(image_counts.values()), palette="Set2")
plt.title("Image Count per Class")
plt.ylabel("Number of Images")
plt.xlabel("Class")
plt.xticks(rotation=15)
plt.show()

"""Display few sample images from each class"""

def show_sample_images(image_paths, class_names, num_images=3):
    plt.figure(figsize=(15, 6))
    for idx, cls in enumerate(class_names):
        for i in range(num_images):
            img_path = image_paths[cls][i]
            img = Image.open(img_path)
            plt.subplot(len(class_names), num_images, idx*num_images + i + 1)
            plt.imshow(img)
            plt.title(cls)
            plt.axis("off")
    plt.tight_layout()
    plt.show()

show_sample_images(image_paths, class_names)

"""Analyze image sizes"""

image_sizes = []
for cls in class_names:
    for path in image_paths[cls][:100]:  # check only first 100 to save time
        img = Image.open(path)
        image_sizes.append(img.size)

widths, heights = zip(*image_sizes)
plt.figure(figsize=(10, 5))
plt.hist(widths, bins=20, alpha=0.6, label='Width')
plt.hist(heights, bins=20, alpha=0.6, label='Height')
plt.title("Image Dimension Distribution")
plt.xlabel("Pixels")
plt.ylabel("Count")
plt.legend()
plt.show()

"""Summary stats"""

#
print("Number of classes:", len(class_names))
print("Total images:", sum(image_counts.values()))
print("Sample image size (WxH):", image_sizes[0])

"""CNN MODEL BUILD"""

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import layers, models
import os

"""PARAMETER"""

img_size = (128, 128)
batch_size = 32

"""IMAGE PREPROCESSING"""

datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2
)

train_gen = datagen.flow_from_directory(
    base_path,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='categorical',
    subset='training',
    shuffle=True,
    seed=42
)

val_gen = datagen.flow_from_directory(
    base_path,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='categorical',
    subset='validation',
    shuffle=False
)

# Class indices
print("Class indices:", train_gen.class_indices)

# CNN Model
from tensorflow.keras import Input

model = models.Sequential([
    Input(shape=(img_size[0], img_size[1], 3)),

    layers.Conv2D(32, (3, 3), activation='relu'),
    layers.MaxPooling2D(2, 2),

    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D(2, 2),

    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D(2, 2),

    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(3, activation='softmax')
])

model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

model.summary()

# Train the model
history = model.fit(
    train_gen,
    epochs=10,
    validation_data=val_gen
)

# Evaluate model
loss, acc = model.evaluate(val_gen)
print(f"\nâœ… Validation Accuracy: {acc:.2f}")

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from sklearn.metrics import classification_report, confusion_matrix
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import layers, models, Input
import os

# Evaluate and predict
val_gen.reset()
predictions = model.predict(val_gen, verbose=1)
y_pred = np.argmax(predictions, axis=1)
y_true = val_gen.classes
class_names = list(val_gen.class_indices.keys())

# Confusion Matrix
cm = confusion_matrix(y_true, y_pred)

# Plot training history
def plot_history(hist):
    plt.figure(figsize=(12, 5))

    # Accuracy plot
    plt.subplot(1, 2, 1)
    plt.plot(hist.history['accuracy'], label='Train Accuracy')
    plt.plot(hist.history['val_accuracy'], label='Val Accuracy')
    plt.title('Model Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()

    # Loss plot
    plt.subplot(1, 2, 2)
    plt.plot(hist.history['loss'], label='Train Loss')
    plt.plot(hist.history['val_loss'], label='Val Loss')
    plt.title('Model Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()

    plt.tight_layout()
    plt.show()

# Plot confusion matrix
def plot_conf_matrix(cm, classes):
    plt.figure(figsize=(6, 5))
    sns.heatmap(cm, annot=True, fmt="d", cmap='Blues', xticklabels=classes, yticklabels=classes)
    plt.title('Confusion Matrix')
    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    plt.show()

#Save the model
model.save('/content/rice_leaf_disease_model.h5')

# Display plots
plot_history(history)
plot_conf_matrix(cm, class_names)

import streamlit as st
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
import numpy as np
from PIL import Image

# Load model
@st.cache_resource
def load_model_custom():
    return load_model("rice_leaf_disease_model.h5")

model = load_model_custom()

# Label penyakit daun (urutannya sesuai model)
class_names = ['Bacterial leaf blight', 'Brown spot', 'Leaf smut']  # ganti sesuai datasetmu

# Judul
st.title("ðŸŒ¿ Deteksi Penyakit Daun Padi")
st.write("Unggah gambar daun padi untuk mendeteksi penyakitnya.")

# Upload gambar
uploaded_file = st.file_uploader("Unggah gambar daun", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    img = Image.open(uploaded_file).convert("RGB")
    st.image(img, caption="Gambar yang diunggah", use_column_width=True)

    if st.button("Deteksi Penyakit"):
        with st.spinner("Mendeteksi..."):
            # Preprocessing
            img_resized = img.resize((128, 128))  # ukuran harus sama dengan saat training
            img_array = image.img_to_array(img_resized)
            img_array = np.expand_dims(img_array, axis=0) / 255.0

            # Prediksi
            prediction = model.predict(img_array)
            class_index = np.argmax(prediction)
            confidence = np.max(prediction)

            # Output
            st.success(f"âœ… Deteksi: **{class_names[class_index]}**")
            st.info(f"Akurasi prediksi: {confidence:.2%}")